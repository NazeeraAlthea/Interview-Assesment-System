{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec6e7bb",
   "metadata": {},
   "source": [
    "# ASR + Speaker Diarization + WER/CER + JSON Output\n",
    "\n",
    "Pipeline ini melakukan:\n",
    "1. Konversi video ke WAV (16kHz mono)\n",
    "2. ASR dengan Whisper\n",
    "3. Speaker diarization dengan `pyannote/speaker-diarization-3.1`\n",
    "4. Penggabungan kata + speaker jadi kalimat lengkap dengan timestamp\n",
    "5. Evaluasi WER & CER menggunakan dataset dari Hugging Face\n",
    "6. Menyimpan output akhir dalam format JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a06fa",
   "metadata": {},
   "source": [
    "## 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c403ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\05_Personal\\Asah by Dicoding\\capstone-project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "import whisper\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pyannote.audio import Pipeline\n",
    "from jiwer import wer, cer\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a5caea",
   "metadata": {},
   "source": [
    "## 2. Konfigurasi Utama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ca89725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path file utama (video / audio)\n",
    "FILE_PATH = 'data/interview_question_5.webm'  # ganti sesuai kebutuhan\n",
    "WAV_PATH = FILE_PATH.rsplit('.', 1)[0] + '.wav'\n",
    "\n",
    "# Model Whisper dan device\n",
    "MODEL_SIZE = 'base.en'  # misal: tiny, base, small, medium\n",
    "DEVICE = 'cpu'          # atau 'cuda' kalau ada GPU\n",
    "\n",
    "# Konfigurasi evaluasi WER/CER (Hugging Face dataset)\n",
    "HF_DATASET_NAME = 'rakshya34/filtered_english_female_voice_v1'  # contoh\n",
    "HF_SPLIT = 'train'  # ganti jika perlu (train/validation/test)\n",
    "MAX_EVAL_SAMPLES = 100  # batasi jumlah sampel untuk demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c4f4dc",
   "metadata": {},
   "source": [
    "## 3. Fungsi Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4605ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(seconds: float) -> str:\n",
    "    \"\"\"Konversi detik ke format H:M:S,ms (00:00:00,000).\"\"\"\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = int(seconds % 60)\n",
    "    ms = int((seconds - int(seconds)) * 1000)\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d},{ms:03d}\"\n",
    "\n",
    "def ensure_wav_16k_mono(input_path: str) -> str:\n",
    "    \"\"\"Pastikan ada file WAV 16kHz mono. Jika belum ada, konversi dengan ffmpeg.\"\"\"\n",
    "    wav_path = input_path.rsplit('.', 1)[0] + '.wav'\n",
    "    if not os.path.exists(wav_path):\n",
    "        print(f'Mengonversi {input_path} ke {wav_path} (16kHz, mono)...')\n",
    "        subprocess.run([\n",
    "            'ffmpeg', '-y', '-i', input_path,\n",
    "            '-ar', '16000', '-ac', '1', wav_path\n",
    "        ], check=True)\n",
    "    else:\n",
    "        print(f'File WAV sudah ada: {wav_path}')\n",
    "    return wav_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f01cd1",
   "metadata": {},
   "source": [
    "## 4. Load Model Whisper & Diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ba96b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memuat pipeline diarisasi 'pyannote/speaker-diarization-3.1'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\05_Personal\\Asah by Dicoding\\capstone-project\\venv\\Lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py:43: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  from speechbrain.pretrained import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline diarisasi berhasil dimuat.\n",
      "Memuat model Whisper 'base.en' di device 'cpu'...\n",
      "Model Whisper berhasil dimuat.\n"
     ]
    }
   ],
   "source": [
    "def load_diarization_pipeline(device: str = 'cpu'):\n",
    "    \"\"\"Load diarization pipeline PyAnnote 3.x.\"\"\"\n",
    "    print(\"Memuat pipeline diarisasi 'pyannote/speaker-diarization-3.1'...\")\n",
    "\n",
    "    # karena kamu sudah huggingface-cli login, tidak perlu token di sini\n",
    "    pipeline = Pipeline.from_pretrained(\n",
    "        \"pyannote/speaker-diarization-3.1\"\n",
    "    )\n",
    "\n",
    "    pipeline.to(torch.device(device))\n",
    "    print(\"Pipeline diarisasi berhasil dimuat.\")\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def load_whisper_model(model_size: str = \"base.en\", device: str = \"cpu\"):\n",
    "    \"\"\"Load Whisper model.\"\"\"\n",
    "    print(f\"Memuat model Whisper '{model_size}' di device '{device}'...\")\n",
    "\n",
    "    model = whisper.load_model(model_size, device=device)\n",
    "\n",
    "    print(\"Model Whisper berhasil dimuat.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Eksekusi\n",
    "diarization_pipeline = load_diarization_pipeline(DEVICE)\n",
    "whisper_model = load_whisper_model(MODEL_SIZE, DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de04fc28",
   "metadata": {},
   "source": [
    "## 5. Proses Diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f321312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File WAV sudah ada: data/interview_question_5.wav\n",
      "\n",
      "Menjalankan diarization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\05_Personal\\Asah by Dicoding\\capstone-project\\venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ..\\aten\\src\\ATen\\native\\ReduceOps.cpp:1760.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diarization selesai dalam 58.58 detik.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.739719</td>\n",
       "      <td>5.363469</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.139719</td>\n",
       "      <td>7.337844</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.793469</td>\n",
       "      <td>10.054719</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.274094</td>\n",
       "      <td>10.611594</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.084094</td>\n",
       "      <td>13.345344</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       start        end     speaker\n",
       "0   0.739719   5.363469  SPEAKER_00\n",
       "1   6.139719   7.337844  SPEAKER_00\n",
       "2   7.793469  10.054719  SPEAKER_00\n",
       "3  10.274094  10.611594  SPEAKER_00\n",
       "4  11.084094  13.345344  SPEAKER_00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_path = ensure_wav_16k_mono(FILE_PATH)\n",
    "\n",
    "print('\\nMenjalankan diarization...')\n",
    "start_diar = time.time()\n",
    "diarization_result = diarization_pipeline(wav_path)\n",
    "end_diar = time.time()\n",
    "print(f'Diarization selesai dalam {end_diar - start_diar:.2f} detik.')\n",
    "\n",
    "speaker_turns = []\n",
    "for turn, _, speaker in diarization_result.itertracks(yield_label=True):\n",
    "    speaker_turns.append({\n",
    "        'start': turn.start,\n",
    "        'end': turn.end,\n",
    "        'speaker': speaker\n",
    "    })\n",
    "\n",
    "speaker_df = pd.DataFrame(speaker_turns)\n",
    "speaker_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5e049",
   "metadata": {},
   "source": [
    "## 6. Proses ASR dengan Whisper (Word Timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ed9c1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Menjalankan transkripsi Whisper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\05_Personal\\Asah by Dicoding\\capstone-project\\venv\\Lib\\site-packages\\whisper\\transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transkripsi selesai dalam 17.45 detik.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'segments', 'language'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nMenjalankan transkripsi Whisper...')\n",
    "start_asr = time.time()\n",
    "asr_result = whisper_model.transcribe(\n",
    "    FILE_PATH,\n",
    "    language='en',\n",
    "    word_timestamps=True\n",
    ")\n",
    "end_asr = time.time()\n",
    "print(f'Transkripsi selesai dalam {end_asr - start_asr:.2f} detik.')\n",
    "\n",
    "asr_result.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bb6556",
   "metadata": {},
   "source": [
    "## 7. Menggabungkan Kata + Speaker menjadi Kalimat Bertimestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8227b4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total kata: 222\n",
      "Total segmen kalimat: 17\n",
      "[00:00:00,000 --> 00:00:00,920] UNKNOWN:  Let's\n",
      "[00:00:00,920 --> 00:00:05,680] SPEAKER_00:  try  the  process  of  building  more  controls.  Let's\n",
      "[00:00:05,680 --> 00:00:06,440] UNKNOWN:  fix\n",
      "[00:00:06,440 --> 00:00:18,500] SPEAKER_00:  it.  See  and  everyone.  So,  at  the  first  time,  of  course,  we  need  to  make  sure  there  are  split,\n",
      "[00:00:19,140 --> 00:00:20,820] UNKNOWN:  the\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "for seg in asr_result.get('segments', []):\n",
    "    for w in seg.get('words', []):\n",
    "        all_words.append(w)\n",
    "\n",
    "print(f'Total kata: {len(all_words)}')\n",
    "\n",
    "word_speaker_mapping = []\n",
    "for word in all_words:\n",
    "    w_start = word['start']\n",
    "    match = speaker_df[(speaker_df['start'] <= w_start) & (speaker_df['end'] >= w_start)]\n",
    "    if not match.empty:\n",
    "        spk = match.iloc[0]['speaker']\n",
    "    else:\n",
    "        spk = 'UNKNOWN'\n",
    "    word_speaker_mapping.append({\n",
    "        'start': word['start'],\n",
    "        'end': word['end'],\n",
    "        'word': word['word'],\n",
    "        'speaker': spk\n",
    "    })\n",
    "\n",
    "final_segments = []\n",
    "current = None\n",
    "\n",
    "for w in word_speaker_mapping:\n",
    "    if current is None:\n",
    "        current = {\n",
    "            'start': w['start'],\n",
    "            'end': w['end'],\n",
    "            'speaker': w['speaker'],\n",
    "            'text': w['word']\n",
    "        }\n",
    "    else:\n",
    "        if w['speaker'] == current['speaker']:\n",
    "            if not current['text'].endswith(' '):\n",
    "                current['text'] += ' '\n",
    "            current['text'] += w['word']\n",
    "            current['end'] = w['end']\n",
    "        else:\n",
    "            final_segments.append(current)\n",
    "            current = {\n",
    "                'start': w['start'],\n",
    "                'end': w['end'],\n",
    "                'speaker': w['speaker'],\n",
    "                'text': w['word']\n",
    "            }\n",
    "\n",
    "if current is not None:\n",
    "    final_segments.append(current)\n",
    "\n",
    "print(f'Total segmen kalimat: {len(final_segments)}')\n",
    "\n",
    "for seg in final_segments[:5]:\n",
    "    print(f\"[{format_time(seg['start'])} --> {format_time(seg['end'])}] {seg['speaker']}: {seg['text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1591ab",
   "metadata": {},
   "source": [
    "## 8. Evaluasi WER & CER dengan Dataset Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df9d4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memuat dataset: rakshya34/filtered_english_female_voice_v1 (train)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 533/533 [00:00<?, ?B/s] \n",
      "Downloading data: 100%|██████████| 18/18 [1:04:01<00:00, 213.42s/files]\n",
      "Generating train split: 100%|██████████| 216130/216130 [00:42<00:00, 5040.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\n",
      "REF: \"The Chronicle\" is supported by the student activity fee and advertising.\n",
      "HYP: The clinical is supported by the student activity few and advertising.\n",
      "---\n",
      "Sample 1\n",
      "REF: He denied all allegations, although he later reached a settlement with Evangelista.\n",
      "HYP: He denied all allegations of all he later reached a certain way to me, a venge on this start.\n",
      "---\n",
      "Sample 2\n",
      "REF: Rock has one son, Alexander John, with his wife Liza.\n",
      "HYP: No Kazwan-san Alexander-John with his wife Lisa.\n",
      "---\n",
      "Sample 3\n",
      "REF: The park features a large pond, skate park and several football pitches.\n",
      "HYP: The park features a large pond, skate park and several football beaches.\n",
      "---\n",
      "Sample 4\n",
      "REF: The Greater Glenmont Civic Association won several awards and grants for its activities.\n",
      "HYP: The Greater Glenmont Civic Association won several awards and grants for its activities.\n",
      "---\n",
      "Sample 5\n",
      "REF: As a part of this initiative Noir repainted several of his original works.\n",
      "HYP: As a part of this initiative, Noa repainted several of his original works.\n",
      "---\n",
      "Sample 6\n",
      "REF: Didn't Charles have any friends?\n",
      "HYP: Didn't Charles have any friends?\n",
      "---\n",
      "Sample 7\n",
      "REF: They're not my children.\n",
      "HYP: They are not my children.\n",
      "---\n",
      "Sample 8\n",
      "REF: He played college basketball for the Houston Baptist Huskies and Wake Forest Demon Deacons.\n",
      "HYP: He played college basketball for the Houston Baptist Huskies and Wake Forest in Montecans.\n",
      "---\n",
      "Sample 9\n",
      "REF: The bones from the mass grave are now stored in the temple.\n",
      "HYP: The bones from the mass grip are now storing the temple.\n",
      "---\n",
      "Sample 10\n",
      "REF: The match was played under Australian rules.\n",
      "HYP: Then match with play under Australian rules.\n",
      "---\n",
      "Sample 11\n",
      "REF: There's a group of unruly teens bumming around in your garden.\n",
      "HYP: There's a group of unruly teens, burming around in your garden.\n",
      "---\n",
      "Sample 12\n",
      "REF: Wilson to measure the angular diameter of the star Betelgeuse.\n",
      "HYP: We'll send to measure the angular diameter of the star but we'll guess.\n",
      "---\n",
      "Sample 13\n",
      "REF: Two other members of the Browne family have been elevated to the peerage.\n",
      "HYP: Two other members of the Brony family have been elevated to the peerage.\n",
      "---\n",
      "Sample 14\n",
      "REF: He also published musical essays, the most important being \"Reminiscenze artistiche\".\n",
      "HYP: He also published musical essays, the most important being Remini sends the artichie.\n",
      "---\n",
      "Sample 15\n",
      "REF: The Belair railway line is also very close to the suburb.\n",
      "HYP: The Belair railway line is also very close to the suburb.\n",
      "---\n",
      "Sample 16\n",
      "REF: She assists Solid Snake in Eastern Europe.\n",
      "HYP: She assists Solid Snake in Eastern Europe.\n",
      "---\n",
      "Sample 17\n",
      "REF: Topical songs are often, but not always, protest songs.\n",
      "HYP: Topical songs are often, but not always, protest songs.\n",
      "---\n",
      "Sample 18\n",
      "REF: He assisted his wife with the founding of the school.\n",
      "HYP: He assisted his wife with the founding of the school.\n",
      "---\n",
      "Sample 19\n",
      "REF: The library's greatest strength, however, lies in its French holdings.\n",
      "HYP: The library's graded strength, however, lines in its friends' holdings.\n",
      "---\n",
      "Sample 20\n",
      "REF: The Capitals were then eliminated by eventual league-champion Woodstock in a five-game division final.\n",
      "HYP: The Capitals were then eliminated by a eventual league champion Woodstock in a five game division final.\n",
      "---\n",
      "Sample 21\n",
      "REF: Designed to draw upon students' innate curiosity, the academic program fuels authentic learning.\n",
      "HYP: Designed to draw upon students in 8 Curiosity, the Academic Program fuels authentic learning.\n",
      "---\n",
      "Sample 22\n",
      "REF: It's a home run!\n",
      "HYP: It's a home run.\n",
      "---\n",
      "Sample 23\n",
      "REF: The monument, surrounded by a park, stands at the east end of Liberty Square.\n",
      "HYP: The monument, surrounded by a park, stands at the east end of Liberty Square.\n",
      "---\n",
      "Sample 24\n",
      "REF: Forest plantations are generally intended for the production of timber and pulpwood.\n",
      "HYP: Forest plantations are generally intended for the production of timber and oak wood.\n",
      "---\n",
      "Sample 25\n",
      "REF: Its full title was The Free Grammar School of Queen Elizabeth.\n",
      "HYP: It's full title with the free grammar score of Queen Elizabeth.\n",
      "---\n",
      "Sample 26\n",
      "REF: The \"Cats\" won a game before being eliminated.\n",
      "HYP: Decats won a game before being eliminated.\n",
      "---\n",
      "Sample 27\n",
      "REF: The Tuam college side subsequently faced Saint Finian's of Mullingar in the All-Ireland final.\n",
      "HYP: The tool collage side subsequently faced the opinions of Malinger in the all Ireland final.\n",
      "---\n",
      "Sample 28\n",
      "REF: \"Twas the Night Before Christmas\" is a hidden track.\n",
      "HYP: To us, the night before Christmas is a hidden track.\n",
      "---\n",
      "Sample 29\n",
      "REF: Ocean Beach was once known as the Haight-Ashbury of San Diego.\n",
      "HYP: Ocean bead was once known as the height ashbury of San Diego.\n",
      "---\n",
      "Sample 30\n",
      "REF: Its county seat is Hartington.\n",
      "HYP: Its congee seeds is hurting ton.\n",
      "---\n",
      "Sample 31\n",
      "REF: It has an approximately hourly service in each direction.\n",
      "HYP: It has an approximately hourly service in each direction.\n",
      "---\n",
      "Sample 32\n",
      "REF: While traveling, they meet Princess Nastoya, the leader of the Scrow, a Vinkus tribe.\n",
      "HYP: While traveling, the meat princess Nastoia, the leader of the scroll, Ovenko's tribe.\n",
      "---\n",
      "Sample 33\n",
      "REF: This resulted in another condominium, this time between Hesse and the Palatinate.\n",
      "HYP: This resulted in another condominium, this time between Hess and the Palatne.\n",
      "---\n",
      "Sample 34\n",
      "REF: Besides being a talented and tactical competitor Zamba was incredibly popular during her reign.\n",
      "HYP: Besides being a talented and tactical competitor, Zambo was incredibly popular during her reign.\n",
      "---\n",
      "Sample 35\n",
      "REF: Coach Gene Shue's eight-man rotation sank more field goals than any other team.\n",
      "HYP: Coach Jean Chiu's 8-man rotation sank more field goals than any other team.\n",
      "---\n",
      "Sample 36\n",
      "REF: The house system is now combined with the system of forms.\n",
      "HYP: The house system is now combined with the system of forms.\n",
      "---\n",
      "Sample 37\n",
      "REF: The last two took interest in Politzer and were influential in his subsequent career.\n",
      "HYP: Last two took interest in Pulitzer and were influential in his subsequent career.\n",
      "---\n",
      "Sample 38\n",
      "REF: Although her office is officially non-partisan, Robison is affiliated with the Democratic Party.\n",
      "HYP: Although her office is officially non-practition, Robison is affiliated with the Democratic Party.\n",
      "---\n",
      "Sample 39\n",
      "REF: This article was reacted to by E C Stuart Baker.\n",
      "HYP: The article was reacted to by E. C. Stuart Theta.\n",
      "---\n",
      "Sample 40\n",
      "REF: He shall set about it tomorrow.\n",
      "HYP: He shall set about it tomorrow.\n",
      "---\n",
      "Sample 41\n",
      "REF: I respect you for it.\n",
      "HYP: I respect you for it.\n",
      "---\n",
      "Sample 42\n",
      "REF: A neurotic girl, sir, I agree.\n",
      "HYP: I'm the erotic girl, sir. I agree.\n",
      "---\n",
      "Sample 43\n",
      "REF: For fifty pounds he had seen his mother that day.\n",
      "HYP: For fifty pounds he had seen his mother that day.\n",
      "---\n",
      "Sample 44\n",
      "REF: He went on to lose the general election to Hefner.\n",
      "HYP: He went on to lose the general election to Hefner.\n",
      "---\n",
      "Sample 45\n",
      "REF: This has since become the train.\n",
      "HYP: This has since become the train.\n",
      "---\n",
      "Sample 46\n",
      "REF: This region is where gold was first discovered in the United States.\n",
      "HYP: This region is where gold was first discovered in the United States.\n",
      "---\n",
      "Sample 47\n",
      "REF: His parents were the comedy double act Callan and Emery.\n",
      "HYP: His parents were the Comedy Double Act, Callan and Emery.\n",
      "---\n",
      "Sample 48\n",
      "REF: Site listing bids are often lengthy and costly putting poorer countries at a disadvantage.\n",
      "HYP: Side listing bids are often lengthy and costly, putting poorer countries at a disadvantage.\n",
      "---\n",
      "Sample 49\n",
      "REF: It has \"a large hool, that resceiveth in hir wombe the thin plates\".\n",
      "HYP: It has a large tool that receives it in her womb, the thin plates.\n",
      "---\n",
      "Sample 50\n",
      "REF: Some are former members of the genus \"Phaseolus\".\n",
      "HYP: Some former members of the Genes faciolus.\n",
      "---\n",
      "Sample 51\n",
      "REF: He has been described by \"The Times\" as \"the very architect of Egyptian chronology\".\n",
      "HYP: He has been described by the times as the very architect of Egyptian chronology.\n",
      "---\n",
      "Sample 52\n",
      "REF: He was a nephew of Rear-Admiral Sir Francis Augustus Collier.\n",
      "HYP: He was a nephew of Rear Admiral Sir Francis Augustus Collier.\n",
      "---\n",
      "Sample 53\n",
      "REF: Leaving for some darn camp in Mississippi.\n",
      "HYP: Leaving for some darn camp in Mississippi.\n",
      "---\n",
      "Sample 54\n",
      "REF: While employed in this role, Johnson won the prestigious Robert F. Kennedy Award.\n",
      "HYP: While employed in this role, Johnson won the prestigious Robert F. Kennedy Award.\n",
      "---\n",
      "Sample 55\n",
      "REF: Samuel Lyons proceeded to subdivide Five Dock Farm into substantial estates.\n",
      "HYP: Samuel Lyons proceeded to subdivide 5-Duck arm into substantial estates.\n",
      "---\n",
      "Sample 56\n",
      "REF: The Tui Tonga decline began due to numerous wars and internal pressure.\n",
      "HYP: The two-tongor decline began due to numerous wars and internal pressure.\n",
      "---\n",
      "Sample 57\n",
      "REF: King Kartavirya Arjuna sent his soldiers to take the cow.\n",
      "HYP: Two cartoheria arjuna sent his soldiers to take the call.\n",
      "---\n",
      "Sample 58\n",
      "REF: Those studies which have been done have largely been of low quality.\n",
      "HYP: Those studies which have been done have largely been of low quality.\n",
      "---\n",
      "Sample 59\n",
      "REF: Calumet Heights was swampy and relatively unoccupied throughout the nineteenth century.\n",
      "HYP: Calumetites was swampy and relatively unoccupied throughout the 19th century.\n",
      "---\n",
      "Sample 60\n",
      "REF: The Israeli Ministry of Foreign Affairs protested the check.\n",
      "HYP: The Israeli Ministry of Foreign Affairs protested the check.\n",
      "---\n",
      "Sample 61\n",
      "REF: Seven countries have hosted the Arab Cup.\n",
      "HYP: Southern countries have hosted the Arab Cup.\n",
      "---\n",
      "Sample 62\n",
      "REF: It has garnered millions of views and has been parodied many times.\n",
      "HYP: It has gone out millions of views and has been parodied many times.\n",
      "---\n",
      "Sample 63\n",
      "REF: The team with the fewest points would be relegated.\n",
      "HYP: The team with the fewest points would be relegated.\n",
      "---\n",
      "Sample 64\n",
      "REF: He was the second generation of the Meilland family to breed and grow roses.\n",
      "HYP: He was the second generation of the male and family to breed and grow roses.\n",
      "---\n",
      "Sample 65\n",
      "REF: My heart is broken for his family.\n",
      "HYP: My heart is a-broken for his family.\n",
      "---\n",
      "Sample 66\n",
      "REF: Throughout the war it was deployed on the Cordoba front.\n",
      "HYP: Throughout the war it was deployed on the Cordoba Front.\n",
      "---\n",
      "Sample 67\n",
      "REF: Teams were not able to face opponents from the same country in the group.\n",
      "HYP: Teams were not able to face opponents from the same country in the group.\n",
      "---\n",
      "Sample 68\n",
      "REF: This attraction opened up a new path up to the Mountain Waves attraction.\n",
      "HYP: This attraction opened up a new path up to the mountain waves attraction.\n",
      "---\n",
      "Sample 69\n",
      "REF: They subsequently formed an oppositional group which aligned itself with the International Left Opposition.\n",
      "HYP: They subsequently formed an oppositional group which aligned itself with the international left opposition.\n",
      "---\n",
      "Sample 70\n",
      "REF: All songs written by Bruce Dickinson and Roy Z, except where noted.\n",
      "HYP: All songs written by Bruce, Nick and Sand and Roy, except were notable.\n",
      "---\n",
      "Sample 71\n",
      "REF: Furthermore, many are owners of Nepal's hotels and motels.\n",
      "HYP: Furthermore, many are orders of Naples, hotels and motels.\n",
      "---\n",
      "Sample 72\n",
      "REF: In organisms it is quickly oxidized to pantothenic acid.\n",
      "HYP: In organism it is quickly oxidized to pentothenic acid.\n",
      "---\n",
      "Sample 73\n",
      "REF: Matute was a university professor.\n",
      "HYP: Machut was a university professor.\n",
      "---\n",
      "Sample 74\n",
      "REF: She scored best in tumbling.\n",
      "HYP: She scored best in tumbling.\n",
      "---\n",
      "Sample 75\n",
      "REF: All four were arrested and were released on bail.\n",
      "HYP: On 4 we're arrested and we're released on bell.\n",
      "---\n",
      "Sample 76\n",
      "REF: He was determined now to maintain a more certain hold upon himself.\n",
      "HYP: He was determined now to maintain a more certain hold upon himself.\n",
      "---\n",
      "Sample 77\n",
      "REF: Now go ahead and tell me in a straightforward way what has happened.\n",
      "HYP: Now go ahead and tell me in a straightforward way what has happened.\n",
      "---\n",
      "Sample 78\n",
      "REF: In the crib the baby sat up and began to prattle.\n",
      "HYP: In the grip the baby set up and began to prattle.\n",
      "---\n",
      "Sample 79\n",
      "REF: She loved the color mauve.\n",
      "HYP: She loved to color more.\n",
      "---\n",
      "Sample 80\n",
      "REF: He moved with his family to Kentucky.\n",
      "HYP: He moved with his family to Kentucky.\n",
      "---\n",
      "Sample 81\n",
      "REF: The artist Marie Walker Last was her niece.\n",
      "HYP: The artist Mary Walker last was her niece.\n",
      "---\n",
      "Sample 82\n",
      "REF: The cause of death was found to be suicide by morphine overdose.\n",
      "HYP: The cause of death was found to be recid by morphine overdose.\n",
      "---\n",
      "Sample 83\n",
      "REF: The cemetery records are held at the London Metropolitan Archives.\n",
      "HYP: The symmetry records are held at the London Metropolitan Archives.\n",
      "---\n",
      "Sample 84\n",
      "REF: If you tackled these outliers that would reduce the artifacts.\n",
      "HYP: If you tackle these outliers, that would reduce the artifacts.\n",
      "---\n",
      "Sample 85\n",
      "REF: Campus organizations exhibited products, technologies, and hold fund raisers for various charity groups.\n",
      "HYP: Campus organization exhibited products, technologies, and home fundraisers for various charity groups.\n",
      "---\n",
      "Sample 86\n",
      "REF: In addition, the program included interviews with former course participants, anti-cultists, and commentators.\n",
      "HYP: In addition, the program included interviews with former course participants, anti-cultists, and commentators.\n",
      "---\n",
      "Sample 87\n",
      "REF: Goldman also said the writer they replaced would not leave the project.\n",
      "HYP: Goldman also said the writer they replaced would not leave the project.\n",
      "---\n",
      "Sample 88\n",
      "REF: Gela asked for the help of Dionysius the First of Syracuse.\n",
      "HYP: Gilla asked for the help of Dionysus, the first of Syracuse.\n",
      "---\n",
      "Sample 89\n",
      "REF: Although she didn't have much skill, she was determined to learn the violin.\n",
      "HYP: Although she didn't have much skill, she was determined to learn the violin.\n",
      "---\n",
      "Sample 90\n",
      "REF: Sorry, I don't know my way around campus yet.\n",
      "HYP: Sorry, I don't know my way around composite.\n",
      "---\n",
      "Sample 91\n",
      "REF: Couple of hours after.\n",
      "HYP: Couple of hours after.\n",
      "---\n",
      "Sample 92\n",
      "REF: In my book of memory\n",
      "HYP: in my book of memory.\n",
      "---\n",
      "Sample 93\n",
      "REF: The nature reserve is visible, but not open to the public.\n",
      "HYP: The natural reserve is visible but not open to the public.\n",
      "---\n",
      "Sample 94\n",
      "REF: In other words, it is a symmetric function of the pair of triangles.\n",
      "HYP: In other words, it is a symmetric function of the pair of triangles.\n",
      "---\n",
      "Sample 95\n",
      "REF: The carpet loom made his name widely known.\n",
      "HYP: The carpet loom made his name widely known.\n",
      "---\n",
      "Sample 96\n",
      "REF: The production of cocoa was largely in the hands of Africans.\n",
      "HYP: The production of Coco was largely in the hands of Africans.\n",
      "---\n",
      "Sample 97\n",
      "REF: Saint's early films were shot in Europe, many for Private Media Group.\n",
      "HYP: Saints early films were shot in Europe, many for private media group.\n",
      "---\n",
      "Sample 98\n",
      "REF: Oklahoma National Guard troops have been sent on training and humanitarian missions to Baku.\n",
      "HYP: Oklahoma National Guard troops have been sent on training and humanitarian missions to BACO.\n",
      "---\n",
      "Sample 99\n",
      "REF: Galvin lived in Barrington, Illinois with his wife, Mary Barnes Galvin.\n",
      "HYP: Galvin lived in Barrington, Illinois with his wife Mary Barnes Galvin.\n",
      "---\n",
      "\n",
      "WER rata-rata: 0.2017\n",
      "CER rata-rata: 0.0736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'wer': 0.20173745173745175, 'cer': 0.07359098228663447, 'num_samples': 100}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "from jiwer import wer, cer\n",
    "\n",
    "def evaluate_on_hf_dataset(dataset_name: str, split: str = 'test', max_samples: int = 10):\n",
    "    \"\"\"Hitung WER & CER rata-rata pada subset dataset Hugging Face.\n",
    "\n",
    "    Asumsi kolom:\n",
    "      - 'audio' berisi info audio (dengan field 'array' dan 'sampling_rate')\n",
    "      - 'text' berisi transkrip ground truth\n",
    "    \"\"\"\n",
    "    print(f'\\nMemuat dataset: {dataset_name} ({split})...')\n",
    "    ds = load_dataset(dataset_name, split=split)\n",
    "\n",
    "    if max_samples is not None:\n",
    "        ds = ds.select(range(min(len(ds), max_samples)))\n",
    "\n",
    "    refs = []\n",
    "    hyps = []\n",
    "\n",
    "    for i, sample in enumerate(ds):\n",
    "        ref_text = sample.get('text', '').strip()\n",
    "        if not ref_text:\n",
    "            continue\n",
    "\n",
    "        audio_info = sample['audio']\n",
    "\n",
    "        # Ambil waveform & sampling rate dari dataset\n",
    "        if isinstance(audio_info, dict) and 'array' in audio_info:\n",
    "            audio_array = np.array(audio_info['array'], dtype=np.float32)\n",
    "            sr = audio_info.get('sampling_rate', ds.features['audio'].sampling_rate)\n",
    "        else:\n",
    "            print(f'Sample {i}: audio tidak punya array yang jelas, dilewati.')\n",
    "            continue\n",
    "\n",
    "        # Resample ke 16kHz (standar Whisper)\n",
    "        target_sr = 16000\n",
    "        if sr != target_sr:\n",
    "            audio_array = librosa.resample(audio_array, orig_sr=sr, target_sr=target_sr)\n",
    "\n",
    "        # Transkripsi langsung dari waveform, tanpa ffmpeg\n",
    "        result = whisper_model.transcribe(\n",
    "            audio_array,\n",
    "            language='en',\n",
    "            fp16=False  # kamu di CPU, jadi pakai FP32\n",
    "        )\n",
    "        hyp_text = result.get('text', '').strip()\n",
    "\n",
    "        if not hyp_text:\n",
    "            continue\n",
    "\n",
    "        refs.append(ref_text)\n",
    "        hyps.append(hyp_text)\n",
    "\n",
    "        print(f'Sample {i}')\n",
    "        print('REF:', ref_text)\n",
    "        print('HYP:', hyp_text)\n",
    "        print('---')\n",
    "\n",
    "    if not refs:\n",
    "        print('Tidak ada pasangan REF-HYP yang valid.')\n",
    "        return None\n",
    "\n",
    "    wer_score = wer(refs, hyps)\n",
    "    cer_score = cer(refs, hyps)\n",
    "\n",
    "    print(f'\\nWER rata-rata: {wer_score:.4f}')\n",
    "    print(f'CER rata-rata: {cer_score:.4f}')\n",
    "\n",
    "    return {\n",
    "        'wer': wer_score,\n",
    "        'cer': cer_score,\n",
    "        'num_samples': len(refs)\n",
    "    }\n",
    "\n",
    "# Panggil seperti biasa:\n",
    "metrics = evaluate_on_hf_dataset(HF_DATASET_NAME, HF_SPLIT, MAX_EVAL_SAMPLES)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff767f8",
   "metadata": {},
   "source": [
    "## 9. Menyimpan Hasil Akhir ke JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d46c4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON disimpan di: outputs\\asr_diarization_output.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'outputs\\\\asr_diarization_output.json'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = {\n",
    "    'file_path': FILE_PATH,\n",
    "    'model_size': MODEL_SIZE,\n",
    "    'device': DEVICE,\n",
    "    'segments': [\n",
    "        {\n",
    "            'start_sec': seg['start'],\n",
    "            'end_sec': seg['end'],\n",
    "            'start_time': format_time(seg['start']),\n",
    "            'end_time': format_time(seg['end']),\n",
    "            'speaker': seg['speaker'],\n",
    "            'text': seg['text']\n",
    "        }\n",
    "        for seg in final_segments\n",
    "    ],\n",
    "    'wer_cer_metrics': metrics\n",
    "}\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "json_path = os.path.join('outputs', 'asr_diarization_output.json')\n",
    "\n",
    "with open(json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f'JSON disimpan di: {json_path}')\n",
    "json_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
